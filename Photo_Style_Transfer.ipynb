{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7pPsDHPE_PF"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dabidou025/Live-Style-Transfer/blob/main/Photo_Style_Transfer.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRMt1Ae6Asc7",
        "outputId": "3b3868b0-e6c4-4a6d-93ae-bad6e0e31a02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 668 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 1.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 211 kB 61.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 332 kB/s \n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 49.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 255 kB 58.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 51.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 63.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 51.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 51.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 856 kB 62.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 44.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 61 kB 499 kB/s \n",
            "\u001b[K     |████████████████████████████████| 58 kB 7.0 MB/s \n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Cloning into 'Live-Style-Transfer'...\n",
            "remote: Enumerating objects: 297, done.\u001b[K\n",
            "remote: Counting objects: 100% (297/297), done.\u001b[K\n",
            "remote: Compressing objects: 100% (226/226), done.\u001b[K\n",
            "remote: Total 297 (delta 148), reused 206 (delta 68), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (297/297), 32.52 MiB | 38.28 MiB/s, done.\n",
            "Resolving deltas: 100% (148/148), done.\n",
            "/content/Live-Style-Transfer\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gradio\n",
        "!git clone https://github.com/dabidou025/Live-Style-Transfer.git\n",
        "%cd Live-Style-Transfer/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBy4brOoF9xC",
        "outputId": "989467b2-546b-4b80-9475-4ad71a54a937"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Running on public URL: https://15503.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(<fastapi.applications.FastAPI at 0x7f041994c650>,\n",
              " 'http://127.0.0.1:7863/',\n",
              " 'https://15503.gradio.app')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import tempfile\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "import gradio as gr\n",
        "import torch\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "from models.stmodel import STModel\n",
        "from predictor import Predictor\n",
        "\n",
        "import argparse\n",
        "from glob import glob\n",
        "import os\n",
        "\n",
        "def predict_gradio(image):\n",
        "    img_size = 512\n",
        "    load_model_path = \"./models/st_model_512_80k_12.pth\"\n",
        "    styles_path = \"./styles/\" \n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    n_styles = len(glob(os.path.join(styles_path, '*.jpg')))\n",
        "    st_model = STModel(n_styles)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    n_styles = len(glob(os.path.join(styles_path, '*.jpg')))\n",
        "    st_model = STModel(n_styles)\n",
        "    if True:\n",
        "        st_model.load_state_dict(torch.load(load_model_path, map_location=device))\n",
        "    st_model = st_model.to(device)\n",
        "\n",
        "    predictor = Predictor(st_model, device, img_size)\n",
        "\n",
        "    list_gen=[]\n",
        "    for s in range(n_styles):\n",
        "        gen = predictor.eval_image(image, s)\n",
        "        list_gen.append(gen)\n",
        "    return list_gen\n",
        "\n",
        "iface = gr.Interface(\n",
        "    predict_gradio,   \n",
        "    [\n",
        "         gr.inputs.Image(type=\"pil\")\n",
        "    ],\n",
        "    [\n",
        "        gr.outputs.Carousel(\"image\", label=\"Style\"),\n",
        "    ],\n",
        "    layout=\"unaligned\",\n",
        "    title=\"Photo Style Transfer\",\n",
        "    description=\"Upload a photo and click on submit to see the 12 styles applied to your photo. Keep in mind that for coding reasons your photo is cropped before the neural net applied the different styles.\",\n",
        "    theme=\"huggingface\",\n",
        "    examples=glob(os.path.join(\"./styles/\", '*.jpg')), \n",
        "    examples_per_page=12,\n",
        "    allow_flagging=\"never\",\n",
        ")\n",
        "\n",
        "iface.launch(inline=False)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Photo_Style_Transfer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
