{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Live_Style_Transfer V3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pRMt1Ae6Asc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02cbc1e3-5954-4c4e-8b7e-8817cb57ec56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Live-Style-Transfer'...\n",
            "remote: Enumerating objects: 178, done.\u001b[K\n",
            "remote: Counting objects: 100% (178/178), done.\u001b[K\n",
            "remote: Compressing objects: 100% (132/132), done.\u001b[K\n",
            "remote: Total 178 (delta 86), reused 133 (delta 43), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (178/178), 30.51 MiB | 31.97 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n",
            "/content/Live-Style-Transfer\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/dabidou025/Live-Style-Transfer.git\n",
        "%cd Live-Style-Transfer/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "\n",
        "    function animate() {\n",
        "      setTimeout(function() {\n",
        "        if (!shutdown) {\n",
        "        requestAnimationFrame(animate);}\n",
        "          if (pendingResolve) {\n",
        "              var result = \"\";\n",
        "              captureCanvas.getContext('2d').drawImage(video, 0, 0, 320, 240);\n",
        "              result = captureCanvas.toDataURL('image/jpeg', 0.5)\n",
        "              var lp = pendingResolve;\n",
        "              pendingResolve = null;\n",
        "              lp(result);\n",
        "            }\n",
        "        }, 1000 / 30);\n",
        "      }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '300px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.visibility = 'hidden';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\", frameRate: { exact: 30 }}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 320; //video.videoWidth;\n",
        "      captureCanvas.height = 240; //video.videoHeight;\n",
        "      window.requestAnimationFrame(animate);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      stream = await createDom();\n",
        "      \n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "\n",
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV mask image into base64 byte string to be overlayed on video stream\n",
        "def mask_to_bytes(mask_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          mask_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  mask_PIL = PIL.Image.fromarray(mask_array, 'RGB')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  mask_PIL.save(iobuf, format='jpeg')\n",
        "  # format return string\n",
        "  mask_bytes = 'data:image/jpeg;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return mask_bytes\n"
      ],
      "metadata": {
        "id": "YTAwfuBHgsEK"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import time\n",
        "from models.stmodel import STModel\n",
        "from predictor import WebcamPredictor\n",
        "import argparse\n",
        "from glob import glob\n",
        "import os\n",
        "\n",
        "def live_style_transfert(style_id):\n",
        "    # start streaming video from webcam\n",
        "    video_stream()\n",
        "    # label for video\n",
        "    label_html = 'Capturing...'\n",
        "\n",
        "    #initialize the Net\n",
        "    img_size = 512\n",
        "    load_model_path = \"./models/st_model_512_80k_12.pth\"\n",
        "    styles_path = \"./styles/\" \n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    n_styles = len(glob(os.path.join(styles_path, '*.jpg')))\n",
        "    st_model = STModel(n_styles)\n",
        "    if True:\n",
        "        st_model.load_state_dict(torch.load(load_model_path, map_location=device))\n",
        "    st_model = st_model.to(device)\n",
        "    predictor = WebcamPredictor(st_model, device) \n",
        "    mask = \"\"\n",
        "\n",
        "    while True:\n",
        "        js_reply = eval_js('stream_frame(\"{}\", \"{}\")'.format(label_html, mask))\n",
        "        if not js_reply:\n",
        "            break\n",
        "        # convert JS response to OpenCV Image\n",
        "        frame = js_to_image(js_reply[\"img\"])\n",
        "        # call our style_predictor on video frame\n",
        "        frame = cv2.resize(frame, (img_size, img_size), fx=0.5, fy=0.5)\n",
        "        frame = np.swapaxes(frame, 0, 2)\n",
        "        gen = predictor.eval_image(frame, style_id)\n",
        "        gen = np.swapaxes(gen, 0, 2)\n",
        "        gen = cv2.resize(gen, (256, 256))\n",
        "        #  draw the mask image\n",
        "        mask_array = np.zeros([256,256, 3], dtype=np.uint8)\n",
        "        mask_array[:,:,:] = (gen[:,:,:]).astype(float) \n",
        "        # convert overlay into bytes\n",
        "        mask_bytes = mask_to_bytes(mask_array)\n",
        "        # update bbox so next frame gets new overlay\n",
        "        mask = mask_bytes\n",
        "\n",
        "#choose a style_id between 1 and 12\n",
        "style_id = 10\n",
        "live_style_transfert(style_id)"
      ],
      "metadata": {
        "id": "NQKy2kz2L5I6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0bd4cecb-cf2e-4f69-ce37-12dee91d9446"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "\n",
              "    function animate() {\n",
              "      setTimeout(function() {\n",
              "        if (!shutdown) {\n",
              "        requestAnimationFrame(animate);}\n",
              "          if (pendingResolve) {\n",
              "              var result = \"\";\n",
              "              captureCanvas.getContext('2d').drawImage(video, 0, 0, 320, 240);\n",
              "              result = captureCanvas.toDataURL('image/jpeg', 0.5)\n",
              "              var lp = pendingResolve;\n",
              "              pendingResolve = null;\n",
              "              lp(result);\n",
              "            }\n",
              "        }, 1000 / 30);\n",
              "      }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '300px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.visibility = 'hidden';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\", frameRate: { exact: 30 }}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'When finished, click here to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 320; //video.videoWidth;\n",
              "      captureCanvas.height = 240; //video.videoHeight;\n",
              "      window.requestAnimationFrame(animate);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      stream = await createDom();\n",
              "      \n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'img': result};\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}